# ARGUS: AI Research Guidance and Understanding System

**ARGUS** is a cloud-deployable research assistant that uses Retrieval-Augmented Generation (RAG) and document similarity to answer technical questions and recommend related papers. It supports PDF ingestion and arXiv metadata parsing.

---

## ğŸ” Features

- **RAG Q&A**: Ask natural language questions over research papers (from PDF and arXiv JSON).
- **Recommendations**: Find similar papers using document embedding + FAISS.
- **Cohere embeddings**: Uses `embed-english-v3.0` for document vectorization.
- **Dockerized**: Easy to deploy on any cloud (AWS EC2, etc.).

---

## ğŸ“ Project Structure

```
ARGUS/
â”‚
â”œâ”€â”€ Notebooks/                 # Jupyter notebooks for development
â”‚   â”œâ”€â”€ step1_RAG_implementation.ipynb
â”‚   â”œâ”€â”€ step2_recommendation_system.ipynb
â”‚   â””â”€â”€ utils_ingest.py        # Shared PDF/JSON processing utilities
â”‚
â”œâ”€â”€ Papers/                    # Local PDF papers
â”œâ”€â”€ archive/                   # arXiv JSON dataset
â”œâ”€â”€ vectorstore/               # FAISS indexes
â”‚   â”œâ”€â”€ faiss_small/           # For factual Q&A (small chunks)
â”‚   â””â”€â”€ faiss_large/           # For reasoning & summaries (large chunks)
â”‚
â”œâ”€â”€ app/                       # FastAPI application
â”‚   â”œâ”€â”€ main.py                # RAG & recommendation endpoints
â”‚   â””â”€â”€ requirements.txt       # API dependencies
â”‚
â”œâ”€â”€ Dockerfile                 # For containerized deployment
â””â”€â”€ README.md                  # This file
```

---

## ğŸ“¥ Ingesting Research Documents

Supports:
- PDF papers (split by page)
- arXiv `.json` snapshot (1 line = 1 paper)

Uses recursive chunking for:
- Small chunks (500 tokens) for **factual** retrieval
- Large chunks (1500 tokens) for **summarization-level** retrieval

---

## ğŸ”  Embedding & Indexing

Embeddings:
- Model: `embed-english-v3.0` from [Cohere](https://cohere.com/)
- Batching done with retry logic (batch size â‰¤ 96)

Vector store:
- FAISS
- Two indexes:
  - `faiss_small` for factual QA
  - `faiss_large` for summarization/recommendation

---

## ğŸ§  RAG Chains

Two RAG chains are created using LangChain:
- `rag_chain_small`: For fast, accurate questions
- `rag_chain_large`: For long-form answers, summaries

---

## ğŸ”— Recommendation System

Similarity search using FAISS with large embeddings:

```python
def recommend_related_papers(query_text, top_k=5):
    results = vector_store.similarity_search(query_text, k=top_k)
```

Input: Paper title or abstract  
Output: List of top-K similar documents

---

## ğŸ³ Docker Setup

**Build the image**:

```bash
sudo docker build -t argus-app .
```

**Run the container**:

```bash
sudo docker run -p 8000:8000 argus-app
```

App will be accessible at: `http://localhost:8000`

---

## ğŸ§ª API Endpoints (FastAPI)

Once deployed, supports:

- `POST /rag/qa` â†’ Ask a question over documents  
- `POST /recommend` â†’ Get similar papers to a query

Example request:

```json
{
  "query": "What are the core contributions of ISAAC?"
}
```

---

## ğŸ” API Keys

Store your keys in a `.env` file:

```
COHERE_API_KEY=your-api-key-here
```

---

## ğŸ“Œ Future Work

- Support for real-time PDF upload
- LLM switching (OpenAI, Mistral, Claude)
- UI frontend with Streamlit or React

---

## ğŸ‘¨â€ğŸ’» Maintainer

- Sri Harsha  
- MS Computer Engineering, Iowa State University

---


